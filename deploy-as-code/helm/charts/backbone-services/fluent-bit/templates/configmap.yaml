apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ template "name" . }}-config
  namespace: {{ .Values.namespace }}
  labels:
    app: {{ template "name" . }}
data:
  # Configuration files: server, input, filters and output
  # ======================================================
  fluent-bit.conf: |
    [SERVICE]
        Flush         1
        Log_Level     info
        Daemon        off
        Parsers_File  parsers.conf
        HTTP_Server   On
        HTTP_Listen   0.0.0.0
        HTTP_Port     2020
    @INCLUDE input-egov-services.conf
    @INCLUDE input-egov-infra.conf
    @INCLUDE filter-kubernetes.conf
    @INCLUDE output-kafka-egov-services.conf
    @INCLUDE output-kafka-infra.conf
    [INPUT]
        Name             tail
        Tag              kube.*
        Path             /var/log/containers/*.log
        Parser           docker
        DB               /var/log/flb_kube.db
        Mem_Buf_Limit    5MB
        Skip_Long_Lines  On
    [OUTPUT]
        Name            es
        Match           *
        Host            elasticsearch-data-v1.es-cluster
        Port            9200
        Index           fluentbit-%Y.%m.%d
        Type            flb
        Logstash_Format On
        Logstash_Prefix fluentbit

  input-egov-services.conf: |
    [INPUT]
        Name              tail
        Tag               kube_egov_services.*
        Path              /var/log/containers/*_egov_*.log
        DB                /var/log/flb_egov_services_log_offsets.db
        Buffer_Max_Size   10MB
        Mem_Buf_Limit     30MB        
        Refresh_Interval  60  
  input-egov-infra.conf: |
    [INPUT]
        Name              tail
        Tag               kube_egov_infra.*
        Path              /var/log/containers/*.log
        Exclude_Path      *.gz,*.1,/var/log/containers/*_egov_*.log,/var/log/containers/*_ispirit_*.log,/var/log/containers/*_kube-system_*.log
        DB                /var/log/flb_egov_infra_log_offsets.db
        Mem_Buf_Limit     3MB
        Skip_Long_Lines   On
        Refresh_Interval  60        
  filter-kubernetes.conf: |
    [FILTER]
        Name                parser
        Match               kube_egov_services.*
        Key_Name            log
        Parser              json
        Reserve_Data        True    
    [FILTER]
        Name                kubernetes
        Match               *
        Kube_URL            https://kubernetes.default.svc.cluster.local:443
        Merge_Log           On
        Annotations         Off
  output-kafka-egov-services.conf: |
    [OUTPUT]
        Name            kafka
        Match           kube_egov_services.*
        Brokers         ${KAFKA_BROKERS}
        Topics          ${KAFKA_EGOV_SERVICES_LOGS_TOPIC} 
        Timestamp_Key   @ts
        # hides errors "Receive failed: Disconnected" when kafka kills idle connections
        rdkafka.log.connection.close false
        # producer buffer is not included in http://fluentbit.io/documentation/0.12/configuration/memory_usage.html#estimating
        rdkafka.queue.buffering.max.kbytes 10240
        # for logs you'll probably want this ot be 0 or 1, not more
        rdkafka.request.required.acks 1  
        rdkafka.max.in.flight.requests.per.connection  5
        rdkafka.retry.backoff.ms  500
        rdkafka.linger.ms  500                  
  output-kafka-infra.conf: |
    [OUTPUT]
        Name            kafka
        Match           kube_egov_infra.*
        Brokers         ${KAFKA_BROKERS}
        Topics          ${KAFKA_EGOV_INFRA_LOGS_TOPIC} 
        Timestamp_Key   @ts      
        # hides errors "Receive failed: Disconnected" when kafka kills idle connections
        rdkafka.log.connection.close false
        # producer buffer is not included in http://fluentbit.io/documentation/0.12/configuration/memory_usage.html#estimating
        rdkafka.queue.buffering.max.kbytes 10240
        # for logs you'll probably want this ot be 0 or 1, not more
        rdkafka.request.required.acks 1
        rdkafka.max.in.flight.requests.per.connection  5
        rdkafka.retry.backoff.ms  500
        rdkafka.linger.ms  500
  parsers.conf: |
    [PARSER]
        Name   apache
        Format regex
        Regex  ^(?<host>[^ ]*) [^ ]* (?<user>[^ ]*) \[(?<time>[^\]]*)\] "(?<method>\S+)(?: +(?<path>[^\"]*?)(?: +\S*)?)?" (?<code>[^ ]*) (?<size>[^ ]*)(?: "(?<referer>[^\"]*)" "(?<agent>[^\"]*)")?$
        Time_Key time
        Time_Format %d/%b/%Y:%H:%M:%S %z
    [PARSER]
        Name   apache2
        Format regex
        Regex  ^(?<host>[^ ]*) [^ ]* (?<user>[^ ]*) \[(?<time>[^\]]*)\] "(?<method>\S+)(?: +(?<path>[^ ]*) +\S*)?" (?<code>[^ ]*) (?<size>[^ ]*)(?: "(?<referer>[^\"]*)" "(?<agent>[^\"]*)")?$
        Time_Key time
        Time_Format %d/%b/%Y:%H:%M:%S %z
    [PARSER]
        Name   apache_error
        Format regex
        Regex  ^\[[^ ]* (?<time>[^\]]*)\] \[(?<level>[^\]]*)\](?: \[pid (?<pid>[^\]]*)\])?( \[client (?<client>[^\]]*)\])? (?<message>.*)$
    [PARSER]
        Name   nginx
        Format regex
        Regex ^(?<remote>[^ ]*) (?<host>[^ ]*) (?<user>[^ ]*) \[(?<time>[^\]]*)\] "(?<method>\S+)(?: +(?<path>[^\"]*?)(?: +\S*)?)?" (?<code>[^ ]*) (?<size>[^ ]*)(?: "(?<referer>[^\"]*)" "(?<agent>[^\"]*)")?$
        Time_Key time
        Time_Format %d/%b/%Y:%H:%M:%S %z
    [PARSER]
        Name        json
        Format      json
        Time_Key    time
        Time_Format %Y-%m-%dT%H:%M:%S.%L
        Time_Keep   On 
    [PARSER]
        Name         docker
        Format       json
        Time_Key     time
        Time_Format  %Y-%m-%dT%H:%M:%S.%L
        Time_Keep    On 
        # Command      |  Decoder | Field | Optional Action
        # =============|==================|=================
        Decode_Field_As   escaped    log    do_next
        Decode_Field_As   json       log
    [PARSER]
        Name        syslog
        Format      regex
        Regex       ^\<(?<pri>[0-9]+)\>(?<time>[^ ]* {1,2}[^ ]* [^ ]*) (?<host>[^ ]*) (?<ident>[a-zA-Z0-9_\/\.\-]*)(?:\[(?<pid>[0-9]+)\])?(?:[^\:]*\:)? *(?<message>.*)$
        Time_Key    time
        Time_Format %b %d %H:%M:%S       
